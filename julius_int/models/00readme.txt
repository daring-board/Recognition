音響モデル・言語モデルについて

1. DNN-HMM音響モデル

※この音響モデルは，Juliusディクテーションキットv4.4のものと同一である．

【ファイル一覧】

W_*.npy, bias_*.npy, prior      DNN定義ファイル
binhmm.SID                      DNN-HMM音響モデル (triphone, HTK形式)
config.lmfb                     特徴量設定ファイル
logicalTri.bin                  Triphoneリスト (バイナリ形式，上記DNN-HMM専用)
norm                            正規化パラメータファイル

【学習データ】

学習データはASJ-JNASコーパス(86時間)およびCSJ(日本語話し言葉コーパス)
模擬講演(292時間)の計378時間である．

特徴量はFBANK 40次元およびその1次・2次差分の計120次元(いわゆるFBANK_D_A)で，
平均と分散の正規化が行われている．adintool等の音声入力時は同梱の正規化
パラメータを適用し(-cmnload)，かつ -cvn オプションを与えること．これらの
特徴量はケプストラムではないが，ケプストラムの正規化フレームワークを流用
して正規化を行う．

【DNN-HMMモデル】

HMMは実質3状態のLR型で，4,874個の状態からなる状態共有モデルである．
状態確率がDNNによって与えられる．

DNNは入力層・出力層および7層の隠れ層を持つニューラルネットワークである．
各層のノード数は次の通りである
  入力層: 1,320 (120次元 x 11フレーム)
  隠れ層: 2,048
  出力層: 4,874 (HMMの状態数)

各層はRBMによる初期化， クロスエントロピ基準による通常のfine tuningと
sMBR基準による系列学習により構築されている．このDNN-HMMモデルは性別
非依存(GID)モデルである．

【作成者】

三村 正人 (京都大学)
2014年1月 (2016年9月 更新)

2. 単語Trigram言語モデル

【ファイル一覧】

csj.bingram           CSJによる言語モデル (Julius bingram形式)
csj.pdp.htkdic        発音辞書

【モデル概要】

学習データは『日本語話し言葉コーパス』(CSJ)の学会・摸擬講演のテキストで
計2,702講演・768万語である．Unidicを用いてテキストを形態素解析したのちに
独自の補正処理を行ったものを単語として用いている．文字コードはEUCである．
「あー」のようなフィラー単語については，認識結果として出力しないよう，
発音辞書であらかじめ出力が空に設定されている．

【作成者】

秋田 祐哉 (京都大学)
2017年10月

以上
